import streamlit as st
from openai import OpenAI
import requests
from bs4 import BeautifulSoup
import os
from vision import *
import tempfile

def read_prompt(file_path):
    with open(file_path, 'r', encoding='utf-8') as file:
        prompt = file.read()
    return prompt

def generate_response(client, model, prompt, user_input):
    if not user_input:
        return "Not found text. Please input text."

    try:
        completion = client.chat.completions.create(
            model=model,  
            messages=[
                {"role": "system", "content": prompt},
                {"role": "user", "content": user_input}
            ],
            temperature=0.1,  
            max_tokens=4096
        )
        return completion.choices[0].message.content.strip()
    except Exception as e:
        raise Exception("í”„ë¡¬í”„íŠ¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

def create_dalle_image(client, prompt):
    try:
        response = client.images.generate(
            model="dall-e-3",
            prompt=prompt,
            size="1024x1024",
            quality="standard",
            n=1,
        )
        return response.data[0].url  
    except Exception as e:
        return str(e)


st.title("ğŸ“ GPT_Maker")
st.markdown('<p style="font-size: small;">Made by Simon</p>', unsafe_allow_html=True)
st.markdown('[WIZnet Tech Blog](https://wiz-tech.tistory.com/)')
st.markdown('[WIZnet Maker Site](https://maker.wiznet.io/)')
st.markdown('[WIZnet Chatbot Test](http://www.iamacorn.p-e.kr:8501/)')
st.markdown("""
    <style>
    button.st-emotion-cache-7ym5gk {
        display: inline-block;   /* ë²„íŠ¼ì„ ì¸ë¼ì¸ ë¸”ë¡ ìš”ì†Œë¡œ ì„¤ì •í•˜ì—¬ ë‚´ìš©ë¬¼ì— ë§ì¶° í¬ê¸° ì¡°ì • */
        min-width: 120px;       /* ë²„íŠ¼ì˜ ìµœì†Œ ë„ˆë¹„ ì„¤ì • */
        margin: 10px;           /* ì£¼ë³€ ìš”ì†Œì™€ì˜ ê°„ê²© ì„¤ì • */
        padding: 8px 16px;      /* ë‚´ë¶€ ì—¬ë°±ì„ ì„¤ì •í•˜ì—¬ ë²„íŠ¼ ë‚´ìš©ë¬¼ê³¼ ê²½ê³„ ì‚¬ì´ì˜ ê³µê°„ì„ ì¡°ì • */
        font-size: 16px;        /* ê¸€ì í¬ê¸° ì„¤ì • */
        background: linear-gradient(to bottom, #a8c461, #36cd9c); /* ê·¸ë¼ë°ì´ì…˜ ì ìš© */
        border: none;
        box-shadow: 3px 3px 10px rgba(0, 0, 0, 0.5);
        color: white;
        font-weight: bold;
        text-align: center;
        cursor: pointer;
        position: relative;
        overflow: hidden;
        white-space: nowrap;     /* ê¸€ìê°€ ë²„íŠ¼ ë°–ìœ¼ë¡œ ë‚˜ê°€ì§€ ì•Šë„ë¡ ì„¤ì • */
    }

    button.st-emotion-cache-7ym5gk::before {
        content: "";
        position: absolute;
        left: 0;
        top: 0;
        width: 100%;
        height: 100%;
        background: linear-gradient(to bottom, rgba(255, 255, 255, 0.2), transparent);
        transform: translateY(-100%);
        transition: transform 0.3s ease;
    }

    button.st-emotion-cache-7ym5gk:hover::before {
        transform: translateY(0);
    }

    button.st-emotion-cache-7ym5gk:hover {
        background: linear-gradient(to bottom, #36cd9c, #a8c461); /* í˜¸ë²„ íš¨ê³¼ */
    }
    </style>
    """, unsafe_allow_html=True)



with st.sidebar:
    model_choice = st.selectbox("ëª¨ë¸ ì„ íƒ", ["gpt-3.5-turbo-16k", "gpt-4","gpt-4-1106-preview"], key="model_select")

    user_api_key = st.text_input("OpenAI API Key", type="password")

    url = st.text_input("í¬ë¡¤ë§ URLì…ë ¥(GPT-4-1106 ê¶Œì¥)", key="url_input")
   
    user_input = st.text_area("ì—¬ê¸°ì— ê¸€ì„ ì…ë ¥í•˜ì„¸ìš”", height=1000, key="input_text")

    char_count = len(user_input)

    st.caption(f"í˜„ì¬ ê¸€ì ìˆ˜: {char_count}")
    
    uploaded_image = st.file_uploader("ì´ë¯¸ì§€ ì—…ë¡œë“œ", type=["png", "jpg", "jpeg"], key="image_uploader")
    print(uploaded_image)

if user_api_key:
    client = OpenAI(api_key=user_api_key)
else:
    st.error("API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")

def crawl_url(url):
    if url:
        try:
            response = requests.get(url)
            soup = BeautifulSoup(response.content, "html.parser")
   
            return soup.get_text()
        except Exception as e:
            return str(e)
    return "URLì´ ì…ë ¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
st.write("")

st.header("WIZnet ChatGPT ê¸€ì“°ê¸° ë„ìš°ë¯¸")
st.write("")
buttons = ["SEO ìµœì í™” ë¸”ë¡œê·¸ ê¸€ ì‘ì„±í•˜ê¸°",
             "ë¬¸ì–´ì²´ë¡œ ì‘ì„±í•˜ê¸°",
             "ê·¸ë£¹ì›¨ì–´ì— ì‘ì„±í•  ê¸€ ìš”ì•½í•˜ê¸°",
             "ì˜ì–´ë¡œ ë²ˆì—­ ì‘ì„±í•˜ê¸°",
             "ì¼ë³¸ì–´ë¡œ ë²ˆì—­ ì‘ì„±í•˜ê¸°",
             "ì´ë©”ì¼ ì „ì²´ê³µì§€ ì‘ì„±í•˜ê¸°",
             "FaQ Data Set ì œì‘í•˜ê¸°",
             "í¬ë¡¤ë§ ë°ì´í„° íŒŒì‹±í•˜ê¸°",
             "DALL-E ì´ë¯¸ì§€ ìƒì„±í•˜ê¸°",
             "GPT-4-Vision ì´ë¯¸ì§€ í•´ì„í•˜ê¸°"
             ]

result_containers = [st.empty() for _ in range(10)]

col1, col2 = st.columns(2)
with col1:
    if st.button("SEO ìµœì í™” ë¸”ë¡œê·¸ ê¸€ ì‘ì„±í•˜ê¸°"):
        try:
            file_path = "prompts/0_prompt.txt"
            prompt = read_prompt(file_path)
            response = generate_response(client, model_choice, prompt, user_input)
            result_containers[0].text_area("ë³€í™˜ê²°ê³¼", response, height=600)
        except Exception as e:
            st.error("ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. Promptë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
            print(e)
with col2:
    if st.button("ë¬¸ì–´ì²´ë¡œ ì‘ì„±í•˜ê¸°"):
        try:
            file_path = "prompts/1_prompt.txt"
            prompt = read_prompt(file_path)
            response = generate_response(client, model_choice, prompt, user_input)
            result_containers[1].text_area("ë³€í™˜ê²°ê³¼", response, height=600)
        except Exception as e:
            st.error("ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. Promptë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")

col1, col2 = st.columns(2)
with col1:
    if st.button("ê·¸ë£¹ì›¨ì–´ì— ì‘ì„±í•  ê¸€ ìš”ì•½í•˜ê¸°"):
        try:
            file_path = "prompts/2_prompt.txt"
            prompt = read_prompt(file_path)
            response = generate_response(client, model_choice, prompt, user_input)
            result_containers[2].text_area("ë³€í™˜ê²°ê³¼", response, height=600)
        except Exception as e:
            st.error("ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. Promptë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
with col2:
    if st.button("ì˜ì–´ë¡œ ë²ˆì—­ ì‘ì„±í•˜ê¸°"):
        try:
            file_path = "prompts/3_prompt.txt"
            prompt = read_prompt(file_path)
            response = generate_response(client, model_choice, prompt, user_input)
            result_containers[3].text_area("ë³€í™˜ê²°ê³¼", response, height=600)
        except Exception as e:
            st.error("ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. Promptë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")

col1, col2 = st.columns(2)
with col1:
    if st.button("ì¼ë³¸ì–´ë¡œ ë²ˆì—­ ì‘ì„±í•˜ê¸°"):
        try:
            file_path = "prompts/4_prompt.txt"
            prompt = read_prompt(file_path)
            response = generate_response(client, model_choice, prompt, user_input)
            result_containers[4].text_area("ë³€í™˜ê²°ê³¼", response, height=600)
        except Exception as e:
            st.error("ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. Promptë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
with col2:
    if st.button("ì´ë©”ì¼ ì „ì²´ê³µì§€ ì‘ì„±í•˜ê¸°"):
        try:
            file_path = "prompts/5_prompt.txt"
            prompt = read_prompt(file_path)
            response = generate_response(client, model_choice, prompt, user_input)
            result_containers[5].text_area("ë³€í™˜ê²°ê³¼", response, height=600)
        except Exception as e:
            st.error("ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. Promptë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")

col1, col2 = st.columns(2)
with col1:
    if st.button("FaQ Data Set ì œì‘í•˜ê¸°"):
        try:
            file_path = "prompts/6_prompt.txt"
            prompt = read_prompt(file_path)
            response = generate_response(client, model_choice, prompt, user_input)
            result_containers[6].text_area("ë³€í™˜ê²°ê³¼", response, height=600)
        except Exception as e:  
            st.error("ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. Promptë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")

with col2:
    if st.button("í¬ë¡¤ë§ ë°ì´í„° íŒŒì‹±í•˜ê¸°"):
        try:
            file_path = "prompts/7_prompt.txt"
            prompt = read_prompt(file_path)
            crawl_data = crawl_url(url)
            print("í”„ë¦°í„°í™•ì¸:",crawl_data)
            response = generate_response(client, model_choice, prompt, crawl_data)
            result_containers[7].text_area("ë³€í™˜ê²°ê³¼", response, height=600)
        except Exception as e:
            st.error("ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. Promptë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")

col1, col2 = st.columns(2)
with col1:
    if st.button("DALL-E ì´ë¯¸ì§€ ìƒì„±í•˜ê¸°"):
        try:
            prompt = user_input 
            image_url = create_dalle_image(client, prompt)
            if image_url:
                result_containers[8].image(image_url, caption=prompt)
            else:
                result_containers[8].write("ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨")
        except Exception as e: 
            st.error(e)
with col2:
    if st.button("GPT-4-Vision ì´ë¯¸ì§€ í•´ì„í•˜ê¸°"):
        try:
            if uploaded_image is not None:
                # ì„ì‹œ íŒŒì¼ ìƒì„±
                with tempfile.NamedTemporaryFile(delete=False, suffix=".jpg") as tmp_file:
                    tmp_file.write(uploaded_image.read())
                    tmp_file_path = tmp_file.name  # ì„ì‹œ íŒŒì¼ì˜ ê²½ë¡œ ì €ì¥
                text = analyze_image_with_gpt4_vision(tmp_file_path, user_api_key)  # ì„ì‹œ íŒŒì¼ ê²½ë¡œë¥¼ í•¨ìˆ˜ì— ì „ë‹¬
                result_containers[9].text_area("ë³€í™˜ê²°ê³¼", text, height=600)

                # ì„ì‹œ íŒŒì¼ ì‚­ì œ (ì˜µì…˜)
                os.remove(tmp_file_path)
            else:
                st.error("ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        except Exception as e:
            st.error(e)

